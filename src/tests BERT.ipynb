{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b21c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b13b128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a72bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')                                                     \n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=658)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017370cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "#model_name = \"sberbank-ai/sbert_large_nlu_ru\"\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=658)\n",
    "#попробуем позже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ceaf084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=658, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0790984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../draft.csv\")\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df['id'] = pd.Series(df['id']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_id = []\n",
    "for id in df['id']:\n",
    "    if len(id) == 10:\n",
    "        g_id.append(str(id)[:4])\n",
    "    else:\n",
    "        g_id.append('0' + str(id)[:3])\n",
    "df['g_id'] = g_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b596a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.value_counts('id')\n",
    "df_count = pd.DataFrame(data={'id': counts.index, 'count': counts.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1e8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.to_csv('../../tnveds_sort.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(lambda x: ' '.join(x.split()[:400]) if len(x.split())>400 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b708368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['label'].apply(lambda x: len(x.split())).hist(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16849258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'][df['label'].apply(lambda x: True if len(x.split()) == 1 else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783679d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "Label_encoder = preprocessing.LabelEncoder()\n",
    "Label_encoder.fit(df['g_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffe27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['g_id'] = Label_encoder.fit_transform(df['g_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60940c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['description', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866eb770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../label_enc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156dcebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../classes.npy', Label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "train = df[:int(len(df)*0.8)]\n",
    "test =  df[int(len(df)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test['labels'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../../train.csv', index=False)\n",
    "test.to_csv('../../test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b090f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f1615b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/yeril/.cache/huggingface/datasets/csv/default-c2d1908b4f31630f/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 333.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "dataset = load_dataset('csv', data_files={'train': '../../train.csv', 'test': '../../test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dca28e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda e: tokenizer(e['description'], truncation = True, max_length=100, padding='max_length'), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "715c8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_style_columns = ['input_ids', 'token_type_ids', 'attention_mask', 'labels']  # \n",
    "dataset = dataset.remove_columns(set(dataset['train'].features.keys()) - set(pytorch_style_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1090b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask', 'input_ids', 'labels', 'token_type_ids'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset['train'].features.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e490d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch', columns=pytorch_style_columns, device='cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3112cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset['train'], shuffle=True, batch_size=1)\n",
    "test_dataloader = DataLoader(dataset['test'], shuffle=False, batch_size=1)\n",
    "#если есть видеопамять около 10гб, можно поставить 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "799638a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeril\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-6)\n",
    "\n",
    "num_epochs = 4\n",
    "\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"constant_with_warmup\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=2000,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55f22b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dcf2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bd9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- \n",
      "epoch 1\n",
      "train loss [10.00%]: 3.701\n",
      "\n",
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13992/13992 [11:42<00:00, 19.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted summary:\n",
      "Test acc: 0.36556603773584906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeril\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.2805728291815288\n",
      "Test recall: 0.36556603773584906\n",
      "Test f1: 0.28694679431793496 \n",
      "\n",
      "train loss [20.00%]: 3.397\n",
      "\n",
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13992/13992 [12:00<00:00, 19.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted summary:\n",
      "Test acc: 0.4159519725557461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeril\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.289303479635917\n",
      "Test recall: 0.4159519725557461\n",
      "Test f1: 0.313635575932986 \n",
      "\n",
      "train loss [29.99%]: 3.156\n",
      "\n",
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13992/13992 [05:13<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted summary:\n",
      "Test acc: 0.44475414522584333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeril\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.3078582376951126\n",
      "Test recall: 0.44475414522584333\n",
      "Test f1: 0.34914344472904557 \n",
      "\n",
      "train loss [39.99%]: 3.027\n",
      "\n",
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13992/13992 [05:19<00:00, 43.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted summary:\n",
      "Test acc: 0.46326472269868496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeril\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.3472276214315194\n",
      "Test recall: 0.46326472269868496\n",
      "Test f1: 0.3687949741848447 \n",
      "\n",
      "train loss [49.99%]: 2.837\n",
      "\n",
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13992/13992 [05:22<00:00, 43.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted summary:\n",
      "Test acc: 0.49942824471126357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeril\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.3961304743426344\n",
      "Test recall: 0.49942824471126357\n",
      "Test f1: 0.40501530915833245 \n",
      "\n",
      "train loss [59.99%]: 2.767\n",
      "\n",
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13992/13992 [05:16<00:00, 44.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted summary:\n",
      "Test acc: 0.5092195540308748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeril\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.38786420861488863\n",
      "Test recall: 0.5092195540308748\n",
      "Test f1: 0.41235310280353094 \n",
      "\n",
      "train loss [69.99%]: 2.612\n",
      "\n",
      "validating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13992/13992 [05:17<00:00, 44.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted summary:\n",
      "Test acc: 0.5417381360777587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeril\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.43189806248974055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeril\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test recall: 0.5417381360777587\n",
      "Test f1: 0.4539413574939823 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0.\n",
    "show_train_loss_every_num_epoch = 0.1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(40*'-', '\\nepoch', epoch+1)\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if i%int(len(train_dataloader)*show_train_loss_every_num_epoch)==int(len(train_dataloader)*show_train_loss_every_num_epoch)-1:\n",
    "            print(f'train loss [{i*100/len(train_dataloader):.2f}%]: {np.array(losses).mean():.3f}')\n",
    "            losses = []\n",
    "            print('\\nvalidating')\n",
    "\n",
    "            f1 = load_metric('f1')\n",
    "            acc = load_metric('accuracy')\n",
    "            precision = load_metric('precision')\n",
    "            recall = load_metric('recall')\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                \n",
    "                for batch in tqdm(test_dataloader):\n",
    "                    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(**batch)\n",
    "                    logits = outputs.logits\n",
    "                    predictions = torch.argmax(logits, dim=-1)\n",
    "                    f1.add_batch(predictions=predictions, references=batch[\"labels\"])    \n",
    "                    acc.add_batch(predictions=predictions, references=batch[\"labels\"])    \n",
    "                    precision.add_batch(predictions=predictions, references=batch[\"labels\"])    \n",
    "                    recall.add_batch(predictions=predictions, references=batch[\"labels\"])    \n",
    "\n",
    "                print('weighted summary:')\n",
    "                print('Test acc:', acc.compute()['accuracy'])\n",
    "                print('Test precision:', precision.compute(average = 'weighted')['precision'])\n",
    "                print('Test recall:', recall.compute(average = 'weighted')['recall'])\n",
    "                f1_weighted = f1.compute(average = 'weighted')['f1']\n",
    "                print('Test f1:', f1_weighted, '\\n')\n",
    "\n",
    "                if f1_weighted > best_f1:\n",
    "                    best_f1 = f1_weighted\n",
    "                    model.save_pretrained(f\"best_model_nov_2021_f1_max={best_f1}_len=100\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_encoder = preprocessing.LabelEncoder()\n",
    "Label_encoder.classes_ = np.load('classes.npy', allow_pickle=True)\n",
    "\n",
    "true = []\n",
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "for batch in tqdm(test_dataloader):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    true += batch[\"labels\"].detach().cpu().numpy().tolist()\n",
    "    preds += predictions.detach().cpu().numpy().tolist()\n",
    "\n",
    "print(classification_report(Label_encoder.inverse_transform(true), Label_encoder.inverse_transform(preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
